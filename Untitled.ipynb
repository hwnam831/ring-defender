{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Models import CNNModel, CNNModelWide, CNNModelDeep, RNNGenerator, Distiller, MLP, RNNModel, QGRU2\n",
    "import Models\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import time\n",
    "import RingDataset\n",
    "from Util import Env, quantizer, shifter, get_parser\n",
    "datadir = 'lotr-data/data/'\n",
    "args = get_parser().parse_args(\"\")\n",
    "env = Env(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zerofiles = os.listdir(\"lotr-data/data/eddsa-0-parsed\")\n",
    "zerolist = []\n",
    "for fname in zerofiles:\n",
    "    with open(datadir + 'eddsa-0-parsed/' + fname, 'r') as f:\n",
    "        zerolist.append([int(n) for n in f])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onefiles = os.listdir(\"lotr-data/data/eddsa-1\")\n",
    "onelist = []\n",
    "for fname in onefiles:\n",
    "    with open(datadir + 'eddsa-1/' + fname, 'r') as f:\n",
    "        onelist.append([int(n) for n in f])\n",
    "print(len(onelist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = min(min([len(s) for s in onelist]), min([len(s) for s in zerolist]))\n",
    "dsize = min(len(zerolist), len(onelist))\n",
    "x_arr = np.zeros([dsize*2, window],dtype=np.float32)\n",
    "y_arr = np.arange(dsize*2)%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(dsize):\n",
    "    x_arr[2*i] = zerolist[i][:window]\n",
    "    x_arr[2*i+1] = onelist[i][:window]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = 16\n",
    "mean = np.median(x_arr)\n",
    "x_arr2 = (x_arr-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentdim = 8\n",
    "gen=Models.QGRU2(42, scale=0.25, dim=studentdim, drop=0.0)\n",
    "assert os.path.isfile('./gans/best_{}_{}_{}.pth'.format('qgru','eddsa',studentdim))\n",
    "gen.load_state_dict(torch.load('./gans/best_{}_{}_{}.pth'.format('qgru','eddsa',studentdim)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.eval()\n",
    "\n",
    "halfstudent = torch.quantization.quantize_dynamic(\n",
    "    gen, {nn.GRUCell, nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "print(halfstudent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentdim = 8\n",
    "gen=Models.QGRU2(42, scale=0.25, dim=studentdim, drop=0.0)\n",
    "assert os.path.isfile('./gans/best_{}_{}.pth'.format('qgru',studentdim))\n",
    "gen.load_state_dict(torch.load('./gans/best_{}_{}.pth'.format('qgru',studentdim)))\n",
    "halfstudent = torch.quantization.quantize_dynamic(\n",
    "    gen.float().cpu(), {nn.GRUCell, nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "with torch.no_grad():\n",
    "    x = torch.Tensor(x_arr2)\n",
    "    shifted = shifter(x)\n",
    "    #train classifier\n",
    "    perturb = halfstudent(shifted).view(shifted.size(0),-1)\n",
    "    perturbed_x = x[:,31:]+perturb\n",
    "    test_x = perturbed_x.numpy()\n",
    "test_y = y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dim = 192\n",
    "prevgen=Models.RNNGenerator2(42, scale=0.25, dim=dim, drop=0.0)\n",
    "assert os.path.isfile('./gans/best_{}_{}_{}.pth'.format('eddsa','adv',dim))\n",
    "prevgen.load_state_dict(torch.load('./gans/best_{}_{}_{}.pth'.format('eddsa','adv',dim)))\n",
    "'''\n",
    "dim=16\n",
    "gen=Models.QGRU2(42, scale=0.25, dim=dim, drop=0.0)\n",
    "assert os.path.isfile('./gans/best_{}_{}_{}.pth'.format('qgru','both',dim))\n",
    "gen.load_state_dict(torch.load('./gans/best_{}_{}_{}.pth'.format('qgru','both',dim)))\n",
    "halfstudent = torch.quantization.quantize_dynamic(\n",
    "    gen.float().cpu(), {nn.GRUCell, nn.Linear}, dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma='auto')\n",
    "clf.fit(train_x, train_y)\n",
    "pred_y = clf.predict(test_x)\n",
    "#tpred_y = clf.predict(train_x)\n",
    "(pred_y == test_y).sum()/len(pred_y)\n",
    "#(tpred_y == train_y).sum()/len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((x_arr, y_arr), open(\"eddsa.pkl\", \"wb\"))\n",
    "pickle.dump((x_arr[:7800], y_arr[:7800]), open(\"eddsa_train.pkl\", \"wb\"))\n",
    "pickle.dump((x_arr[7800:8800], y_arr[7800:8800]), open(\"eddsa_valid.pkl\", \"wb\"))\n",
    "pickle.dump((x_arr[8800:], y_arr[8800:]), open(\"eddsa_test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testset =  RingDataset.EDDSADataset('eddsa'+'_test.pkl')\n",
    "valset =  RingDataset.EDDSADataset('eddsa'+'_valid.pkl')\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=128, num_workers=4)\n",
    "valloader = DataLoader(valset, batch_size=128, num_workers=4)\n",
    "\n",
    "cooldown = 100\n",
    "#halfstudent.eval()\n",
    "gen_test=Models.RNNGenerator2(testset.window, scale=0.25, dim=192, drop=0).cuda()\n",
    "optim_g_t = torch.optim.Adam(gen_test.parameters(), lr=2e-5)\n",
    "for e in range(50):\n",
    "        gen_test.train()\n",
    "        for x,y in valloader:\n",
    "            xdata, ydata = x.cuda(), y.cuda()\n",
    "            shifted = shifter(xdata)\n",
    "            #train classifier\n",
    "            optim_g_t.zero_grad()\n",
    "            perturb2 = halfstudent(shifted.cpu()).view(shifted.size(0),-1).cuda()\n",
    "            perturb = gen_test(shifted).view(shifted.size(0),-1)\n",
    "            loss_d = nn.functional.mse_loss(perturb, perturb2)\n",
    "            loss_d.backward()\n",
    "            optim_g_t.step()\n",
    "for _ in range(3):\n",
    "    #classifier_test = CNNModel(42, dim=256).cuda()\n",
    "    classifier_test = RNNModel(testset.window, dim=256).cuda()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optim_g_t = torch.optim.Adam(gen_test.parameters(), lr=2e-5)\n",
    "    lastacc = 0.0\n",
    "    lastnorm = 0.0\n",
    "    optim_c2 = torch.optim.Adam(classifier_test.parameters(), lr=2e-5)\n",
    "    for e in range(cooldown):\n",
    "        classifier_test.train()\n",
    "        gen_test.train()\n",
    "        for x,y in valloader:\n",
    "            xdata, ydata = x.cuda(), y.cuda()\n",
    "            shifted = shifter(xdata)\n",
    "            #train classifier\n",
    "            optim_c2.zero_grad()\n",
    "            optim_g_t.zero_grad()\n",
    "            perturb2 = halfstudent(shifted.cpu()).view(shifted.size(0),-1).cuda()\n",
    "            perturb = gen_test(shifted).view(shifted.size(0),-1)\n",
    "            #perturb = gen(xdata[:,31:])\n",
    "            #interleaving?\n",
    "            output = classifier_test(xdata[:,31:]+perturb.detach().float())\n",
    "            loss_c = criterion(output, ydata)\n",
    "            loss_c.backward()\n",
    "            optim_c2.step()\n",
    "            loss_d = nn.functional.mse_loss(perturb, perturb2)\n",
    "            loss_d.backward()\n",
    "            optim_g_t.step()\n",
    "\n",
    "\n",
    "        mloss = 0.0\n",
    "        totcorrect = 0\n",
    "        totcount = 0\n",
    "        mnorm = 0.0\n",
    "        zerocorrect = 0\n",
    "        zerocount = 0\n",
    "        onecorrect = 0\n",
    "        onecount = 0\n",
    "        #evaluate classifier\n",
    "\n",
    "        with torch.no_grad():\n",
    "            gen_test.eval()\n",
    "            classifier_test.eval()\n",
    "            for x,y in testloader:\n",
    "                xdata, ydata = x.cuda(), y.cuda()\n",
    "                shifted = shifter(xdata.cpu())\n",
    "                perturb = halfstudent(shifted).view(shifted.size(0),-1).cuda()\n",
    "                perturb = quantizer(perturb)\n",
    "                #perturb = gen(xdata[:,31:])\n",
    "                norm = torch.mean(perturb)\n",
    "                output = classifier_test(xdata[:,31:]+perturb.float())\n",
    "                loss_c = criterion(output, ydata)\n",
    "                pred = output.argmax(axis=-1)\n",
    "                mnorm += norm.item()/len(testloader)\n",
    "                mloss += loss_c.item()/len(testloader)\n",
    "                #macc += ((pred==ydata).sum().float()/pred.nelement()).item()/len(testloader)\n",
    "                totcorrect += (pred==ydata).sum().item()\n",
    "                totcount += y.size(0)\n",
    "                zerocorrect += ((pred==0)*(ydata==0)).sum().item()\n",
    "                zerocount += (ydata==0).sum().item()\n",
    "                onecorrect += ((pred==1)*(ydata==1)).sum().item()\n",
    "                onecount += (ydata==1).sum().item()\n",
    "            macc = float(totcorrect)/totcount\n",
    "            zacc = float(zerocorrect)/zerocount\n",
    "            oacc = float(onecorrect)/onecount\n",
    "            if (e+1)%10 == 0:\n",
    "                print(\"epoch {} \\t zacc {:.6f}\\t oneacc {:.6f}\\t acc {:.6f}\\t Avg perturb {:.6f}\\n\".format(\\\n",
    "                        e+1, zacc, oacc, (zacc+oacc)/2, mnorm))\n",
    "            if cooldown - e <= 10:\n",
    "                lastacc += macc/10\n",
    "                lastnorm += mnorm/10\n",
    "            \n",
    "    print(\"Last 10 acc: {:.6f}\\t perturb: {:.6f}\".format(lastacc,lastnorm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf2 = KNeighborsClassifier(n_neighbors=25)\n",
    "clf2.fit(train_x, train_y)\n",
    "pred_y = clf2.predict(test_x)\n",
    "#tpred_y = clf.predict(train_x)\n",
    "(pred_y == test_y).sum()/len(pred_y)\n",
    "#(tpred_y == train_y).sum()/len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "train_x = []\n",
    "train_y = []\n",
    "test_x = []\n",
    "test_y = []\n",
    "with torch.no_grad():\n",
    "    for x,y in env.valloader:\n",
    "        xdata= x.cuda()\n",
    "        shifted = shifter(xdata, args.history)\n",
    "        #train classifier\n",
    "        perturb = gen_test(shifted).view(shifted.size(0),-1)\n",
    "        perturb = quantizer(perturb)\n",
    "        perturbed_x = xdata[:,args.history-1:]+perturb\n",
    "        for p in perturbed_x:\n",
    "            train_x.append(p.cpu().numpy())\n",
    "        for y_i in y:\n",
    "            train_y.append(y_i.item())\n",
    "    for x,y in env.testloader:\n",
    "        xdata= x\n",
    "        shifted = shifter(xdata, args.history)\n",
    "        #train classifier\n",
    "        perturb = halfstudent(shifted).view(shifted.size(0),-1)\n",
    "        perturb = quantizer(perturb)\n",
    "        perturbed_x = xdata[:,args.history-1:]+perturb.float()\n",
    "        for p in perturbed_x:\n",
    "            test_x.append(p.cpu().numpy())\n",
    "        for y_i in y:\n",
    "            test_y.append(y_i.item())\n",
    "clf = svm.SVC(gamma='auto')\n",
    "clf.fit(train_x, train_y)\n",
    "pred_y = clf.predict(test_x)\n",
    "\n",
    "svmacc = (pred_y == test_y).sum()/len(pred_y)\n",
    "print(\"SVM acc: {:.6f}\".format(svmacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(halfstudent)(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
