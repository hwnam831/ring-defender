{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RingDataset\n",
    "from Models import CNNModel, RNNGenerator, Distiller, MLP, RNNModel\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset =  RingDataset.RingDataset('core4ToSlice3_test.pkl', threshold=42)\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=256, num_workers=4)\n",
    "classifier_test = CNNModel(42, dim=256).cuda()\n",
    "\n",
    "gen=RNNGenerator(42, scale=0.25, dim=16, drop=0.0)\n",
    "assert os.path.isfile('./models/best_{}_{}.pth'.format('cmp', 16))\n",
    "gen.load_state_dict(torch.load('./models/best_{}_{}.pth'.format('cmp', 16)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifter(arr, window=32):\n",
    "    dup = arr[:,None,:].expand(arr.size(0), arr.size(1)+1, arr.size(1))\n",
    "    dup2 = dup.reshape(arr.size(0), arr.size(1), arr.size(1)+1)\n",
    "    shifted = dup2[:,:window,:-window]\n",
    "    return shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNGen2(nn.Module):\n",
    "    def __init__(self, gen):\n",
    "        super().__init__()\n",
    "        self.encoder = gen.encoder\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.resblock = gen.resblock\n",
    "\n",
    "        self.decoder = gen.decoder\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters())\n",
    "        return weight.new_zeros(2, bsz, 16)\n",
    "                \n",
    "    def forward(self, x, hidden):\n",
    "        x = self.quant(x)\n",
    "        encoded = self.encoder(x.permute(0,2,1)) #N,C,S -> N,S,C\n",
    "        hidden = self.quant(hidden)\n",
    "        res, hidden = self.resblock(encoded, hidden)\n",
    "        out = encoded + res #N,S,C\n",
    "        out = self.decoder(out).view(out.size(0),-1)\n",
    "        #out = out + self.scale*torch.randn_like(out)\n",
    "        #out = out + noise\n",
    "        \n",
    "        return self.dequant(torch.relu(out))\n",
    "gen2 = RNNGen2(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNGen2(\n",
      "  (encoder): Sequential(\n",
      "    (0): DynamicQuantizedLinear(in_features=32, out_features=16, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (quant): QuantStub()\n",
      "  (resblock): GRU(16, 16, num_layers=2, batch_first=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): DynamicQuantizedLinear(in_features=16, out_features=1, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  )\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "tensor([[  84.5053,   50.7485,    0.0000,  ...,  857.9224,  858.8124,\n",
      "         1192.4384],\n",
      "        [   0.0000,    0.0000,    0.0000,  ...,  526.6487,  929.5681,\n",
      "          857.4774],\n",
      "        [  99.5083,    0.0000,    0.0000,  ..., 1119.3942, 1075.4023,\n",
      "         1067.2015],\n",
      "        ...,\n",
      "        [  13.8767,    0.0000,    0.0000,  ...,  700.5181,  895.3664,\n",
      "         1115.3892],\n",
      "        [   0.0000,    0.0000,    0.0000,  ...,  793.5240,  790.4725,\n",
      "         1173.6211],\n",
      "        [ 570.7040,    0.0000,    0.0000,  ...,    0.0000,  539.2359,\n",
      "         1044.5063]])\n"
     ]
    }
   ],
   "source": [
    "model = gen2\n",
    "model.eval()\n",
    "\n",
    "model_int8 = torch.quantization.quantize_dynamic(\n",
    "    model, {nn.GRU, nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "print(quantized_model)\n",
    "\n",
    "input_fp32, _ = next(iter(testloader))\n",
    "hidden_fp32 = gen2.init_hidden(input_fp32.size(0))\n",
    "shifted = shifter(input_fp32)\n",
    "\n",
    "'''\n",
    "model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "\n",
    "# Prepare the model for static quantization. This inserts observers in\n",
    "# the model that will observe activation tensors during calibration.\n",
    "model_fp32_prepared = torch.quantization.prepare(model)\n",
    "\n",
    "# calibrate the prepared model to determine quantization parameters for activations\n",
    "# in a real world setting, the calibration would be done with a representative dataset\n",
    "\n",
    "model_fp32_prepared(shifted, hidden_fp32)\n",
    "\n",
    "# Convert the observed model to a quantized model. This does several things:\n",
    "# quantizes the weights, computes and stores the scale and bias value to be\n",
    "# used with each activation tensor, and replaces key operators with quantized\n",
    "# implementations.\n",
    "model_int8 = torch.quantization.convert(model_fp32_prepared)\n",
    "\n",
    "# run the model, relevant calculations will happen in int8\n",
    "'''\n",
    "\n",
    "\n",
    "# run the model, relevant calculations will happen in int8\n",
    "res = model_int8(shifted, hidden_fp32)\n",
    "res2 = model(shifted, hidden_fp32)\n",
    "print(res*256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'qint8'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2f57de367ac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mq2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'qint8'"
     ]
    }
   ],
   "source": [
    "quant = torch.quantization.QuantStub()\n",
    "a = torch.randn(8)\n",
    "q = quant(a)\n",
    "q2 = a.qint8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
